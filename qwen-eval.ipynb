{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baa110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "ds = load_dataset(\"IUTVanguard/PhysicsEval\", split=\"test\")\n",
    "\n",
    "def filter_category(row):\n",
    "    return row[\"category\"] in [\n",
    "        \"Classical Mechanics and Dynamics\",\n",
    "        \"Fluid Mechanics and Continuum Dynamics\"\n",
    "    ]\n",
    "\n",
    "filtered_ds = ds.filter(filter_category)\n",
    "\n",
    "print(f\"Filtered dataset size: {len(filtered_ds)}\")\n",
    "\n",
    "\n",
    "\n",
    "model_name = \"ojus1/Qwen3-0.6B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "OUTPUT_FILE = \"qwen_physics_outputs.jsonl\"\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for row in tqdm(filtered_ds):\n",
    "\n",
    "        prompt = row[\"simplified_problem_statement\"]\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "          messages,\n",
    "          add_generation_prompt=True,\n",
    "          tokenize=True,\n",
    "          return_dict=True,\n",
    "          return_tensors=\"pt\",\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=5000\n",
    "            )\n",
    "\n",
    "        gen_text = tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "\n",
    "        record = {\n",
    "            \"problem_id\": row[\"Problem_ID\"],\n",
    "            \"category\": row[\"category\"],\n",
    "            \"question\": row[\"simplified_problem_statement\"],\n",
    "            \"model_output\": gen_text,\n",
    "            \"reference_answer\": row[\"final_answers_in_brief\"],\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26530a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jsonl2json\n",
      "  Using cached jsonl2json-1.0.0-py3-none-any.whl (3.9 kB)\n",
      "Installing collected packages: jsonl2json\n",
      "Successfully installed jsonl2json-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ransformers (c:\\users\\dhruva rao\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: C:\\Program Files\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install jsonl2json\n",
    "\n",
    "from jsonl2json import JsonlToJsonFormatter\n",
    "\n",
    "jsonl = JsonlToJsonFormatter('qwen3-0.6B_eval.jsonl', 'qwen3-0.6B_eval.json')\n",
    "jsonl.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e654f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
      "     -------------------------------------- 521.0/521.0 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting packaging>=20.9\n",
      "  Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-win_amd64.whl (158 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.20.2-py3-none-any.whl (16 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Collecting shellingham\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting tqdm>=4.42.1\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting typer-slim\n",
      "  Downloading typer_slim-0.21.0-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.2/47.2 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "     -------------------------------------- 152.9/152.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting idna\n",
      "  Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "     -------------------------------------- 113.4/113.4 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting h11>=0.16\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "     -------------------------------------- 108.3/108.3 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Using cached exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-extensions, shellingham, pyyaml, packaging, idna, hf-xet, h11, fsspec, filelock, colorama, certifi, tqdm, httpcore, exceptiongroup, click, typer-slim, anyio, httpx, huggingface_hub\n",
      "Successfully installed anyio-4.12.0 certifi-2026.1.4 click-8.3.1 colorama-0.4.6 exceptiongroup-1.3.1 filelock-3.20.2 fsspec-2025.12.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-1.2.3 idna-3.11 packaging-25.0 pyyaml-6.0.3 shellingham-1.5.4 tqdm-4.67.1 typer-slim-0.21.0 typing-extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc82317d67fa46e5a395371fbc5f1781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install huggingface_hub \n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10135590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e2395512144f1abfde1f30a8eeff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4ea4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/DrDrunkenstein22/qwen_eval_ans/commit/3c357378f0eb83a6d5701071cd74d86be657ba93', commit_message='Upload qwen-0.6B_ans_physics_eval with huggingface_hub', commit_description='', oid='3c357378f0eb83a6d5701071cd74d86be657ba93', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/DrDrunkenstein22/qwen_eval_ans', endpoint='https://huggingface.co', repo_type='dataset', repo_id='DrDrunkenstein22/qwen_eval_ans'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=r\"D:\\physics-reasoning\\smol-phy-reasoning\\qwen3-0.6B_eval.jsonl\",\n",
    "    path_in_repo=\"qwen-0.6B_ans_physics_eval\",\n",
    "    repo_id=\"DrDrunkenstein22/qwen_eval_ans\",\n",
    "    repo_type=\"dataset\",\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4db5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwen revised eval answers set w/ elaborate solution steps for comparison \n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "ds = load_dataset(\"IUTVanguard/PhysicsEval\", split=\"test\")\n",
    "\n",
    "def filter_category(row):\n",
    "    return row[\"category\"] in [\n",
    "        \"Classical Mechanics and Dynamics\",\n",
    "        \"Fluid Mechanics and Continuum Dynamics\"\n",
    "    ]\n",
    "\n",
    "filtered_ds = ds.filter(filter_category)\n",
    "print(f\"Filtered dataset size: {len(filtered_ds)}\")\n",
    "\n",
    "model_name = \"ojus1/Qwen3-0.6B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"balanced\"   # on kaggle 2*t4 gpus faster than auto device mapping \n",
    ")\n",
    "model.eval()\n",
    "\n",
    "OUTPUT_FILE = \"/kaggle/working/qwen_final_eval.json\"\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for row in tqdm(filtered_ds):\n",
    "        prompt = row[\"simplified_problem_statement\"]\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        inputs = tokenizer.apply_chat_template(\n",
    "          messages,\n",
    "          add_generation_prompt=True,\n",
    "          tokenize=True,\n",
    "          return_dict=True,\n",
    "          return_tensors=\"pt\",\n",
    "        ).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=2048, \n",
    "                do_sample=False, \n",
    "                temperature=1.0\n",
    "            )\n",
    "        \n",
    "        gen_text = tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "        \n",
    "        record = {\n",
    "            \"problem_id\": row[\"Problem_ID\"],\n",
    "            \"category\": row[\"category\"],\n",
    "            \"question\": row[\"simplified_problem_statement\"],\n",
    "            \"model_output\": gen_text,\n",
    "            \"elaborate_solution\": row[\"elaborated_solution_steps\"], \n",
    "            \"reference_answer\": row[\"final_answers_in_brief\"],\n",
    "        }\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1ce09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 01:50:03,928 - INFO - Found 473 items to evaluate\n",
      "2026-01-08 01:50:03,960 - INFO - Processing item 1/473: 010e7e8d-e9e0-4c65-a51b-9a906b13b160\n",
      "2026-01-08 01:50:07,078 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:50:07,096 - INFO - Retrying request to /chat/completions in 0.443823 seconds\n",
      "2026-01-08 01:50:09,861 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:50:09,864 - INFO - Retrying request to /chat/completions in 0.908772 seconds\n",
      "2026-01-08 01:50:52,853 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:50:52,863 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"010e7e8d-e9e0-4c65-a51b-9a906b13b160\",\\n  \"mathematical_accuracy\": 2,\\n  \"logical_consistency\": 3,\\n  \"completeness\": 3,\\n  \"clarity_and_coherence\": 4,\\n  \"formulas_principles\": 2,\\n  \"assumptions_made\": 3,\\n  \"overall_correctness\": 4\\n}\\n```'\n",
      "2026-01-08 01:50:52,866 - INFO - Evaluated 010e7e8d-e9e0-4c65-a51b-9a906b13b160: Overall correctness = 4/10\n",
      "2026-01-08 01:50:52,867 - INFO - Processing item 2/473: 812b76e0-1233-4840-ac99-ff448e2aefde\n",
      "2026-01-08 01:50:55,189 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:50:55,192 - INFO - Retrying request to /chat/completions in 0.487922 seconds\n",
      "2026-01-08 01:51:26,864 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:51:26,869 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"812b76e0-1233-4840-ac99-ff448e2aefde\",\\n  \"mathematical_accuracy\": 5,\\n  \"logical_consistency\": 5,\\n  \"completeness\": 5,\\n  \"clarity_and_coherence\": 5,\\n  \"formulas_principles\": 5,\\n  \"assumptions_made\": 5,\\n  \"overall_correctness\": 10\\n}\\n```'\n",
      "2026-01-08 01:51:26,873 - INFO - Evaluated 812b76e0-1233-4840-ac99-ff448e2aefde: Overall correctness = 10/10\n",
      "2026-01-08 01:51:26,874 - INFO - Processing item 3/473: b1d9aca6-5e09-48c3-85e3-a796c7fd0e90\n",
      "2026-01-08 01:52:11,467 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:52:11,472 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"b1d9aca6-5e09-48c3-85e3-a796c7fd0e90\",\\n  \"mathematical_accuracy\": 1,\\n  \"logical_consistency\": 1,\\n  \"completeness\": 2,\\n  \"clarity_and_coherence\": 3,\\n  \"formulas_principles\": 1,\\n  \"assumptions_made\": 1,\\n  \"overall_correctness\": 1\\n}\\n```'\n",
      "2026-01-08 01:52:11,474 - INFO - Evaluated b1d9aca6-5e09-48c3-85e3-a796c7fd0e90: Overall correctness = 1/10\n",
      "2026-01-08 01:52:11,475 - INFO - Processing item 4/473: 5ae3f3f6-82a1-40cf-8887-ca0c76724f8c\n",
      "2026-01-08 01:52:15,019 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:52:15,025 - INFO - Retrying request to /chat/completions in 0.389762 seconds\n",
      "2026-01-08 01:52:17,436 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:52:17,439 - INFO - Retrying request to /chat/completions in 0.817637 seconds\n",
      "2026-01-08 01:53:41,110 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:53:41,114 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"5ae3f3f6-82a1-40cf-8887-ca0c76724f8c\",\\n  \"mathematical_accuracy\": 2,\\n  \"logical_consistency\": 4,\\n  \"completeness\": 3,\\n  \"clarity_and_coherence\": 5,\\n  \"formulas_principles\": 2,\\n  \"assumptions_made\": 2,\\n  \"overall_correctness\": 2\\n}\\n```'\n",
      "2026-01-08 01:53:41,117 - INFO - Evaluated 5ae3f3f6-82a1-40cf-8887-ca0c76724f8c: Overall correctness = 2/10\n",
      "2026-01-08 01:53:41,118 - INFO - Processing item 5/473: c2b9f498-d673-4429-85e9-8bbbc0c8fcb0\n",
      "2026-01-08 01:54:14,899 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:54:14,903 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"c2b9f498-d673-4429-85e9-8bbbc0c8fcb0\",\\n  \"mathematical_accuracy\": 1,\\n  \"logical_consistency\": 3,\\n  \"completeness\": 2,\\n  \"clarity_and_coherence\": 3,\\n  \"formulas_principles\": 2,\\n  \"assumptions_made\": 2,\\n  \"overall_correctness\": 2\\n}\\n```'\n",
      "2026-01-08 01:54:14,905 - INFO - Evaluated c2b9f498-d673-4429-85e9-8bbbc0c8fcb0: Overall correctness = 2/10\n",
      "2026-01-08 01:54:14,906 - INFO - Processing item 6/473: 451dcaf9-3155-465a-ba7b-373fad376519\n",
      "2026-01-08 01:54:17,140 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:54:17,144 - INFO - Retrying request to /chat/completions in 0.485096 seconds\n",
      "2026-01-08 01:54:56,872 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2026-01-08 01:54:56,876 - INFO - RAW MODEL OUTPUT:\n",
      "'```json\\n{\\n  \"problem_id\": \"451dcaf9-3155-465a-ba7b-373fad376519\",\\n  \"mathematical_accuracy\": 1,\\n  \"logical_consistency\": 1,\\n  \"completeness\": 2,\\n  \"clarity_and_coherence\": 1,\\n  \"formulas_principles\": 1,\\n  \"assumptions_made\": 1,\\n  \"overall_correctness\": 1\\n}\\n```'\n",
      "2026-01-08 01:54:56,878 - INFO - Evaluated 451dcaf9-3155-465a-ba7b-373fad376519: Overall correctness = 1/10\n",
      "2026-01-08 01:54:56,879 - INFO - Processing item 7/473: e8ccd00e-8ac7-4897-8a06-5ce6a3a80310\n",
      "2026-01-08 01:54:59,621 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:54:59,628 - INFO - Retrying request to /chat/completions in 0.420591 seconds\n",
      "2026-01-08 01:55:02,340 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n",
      "2026-01-08 01:55:02,343 - INFO - Retrying request to /chat/completions in 0.912480 seconds\n",
      "2026-01-08 01:55:05,523 - INFO - HTTP Request: POST https://api.anannas.ai/v1/chat/completions \"HTTP/1.1 503 Service Unavailable\"\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'all completion attempts failed: glm-4.5-flash (service temporarily unavailable due to high demand. Please retry in a moment)', 'type': 'api_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 239\u001b[0m\n\u001b[0;32m    236\u001b[0m input_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphysics-reasoning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msmol-phy-reasoning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqwen_final_phy_eval.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m output_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphysics-reasoning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msmol-phy-reasoning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqwen_final_phy_eval_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_jsonl\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluation Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal items evaluated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 176\u001b[0m, in \u001b[0;36mprocess_jsonl\u001b[1;34m(in_path, out_path)\u001b[0m\n\u001b[0;32m    167\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ids_left)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproblem_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    169\u001b[0m prompt \u001b[38;5;241m=\u001b[39m fetch_eval_prompt(\n\u001b[0;32m    170\u001b[0m     problem_id,\n\u001b[0;32m    171\u001b[0m     item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melaborate_solution\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    172\u001b[0m     item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    173\u001b[0m     item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    174\u001b[0m )\n\u001b[1;32m--> 176\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglm-4.5-flash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_schema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_schema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphysics_evaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstring\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmathematical_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogical_consistency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompleteness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclarity_and_coherence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformulas_principles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massumptions_made\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverall_correctness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequired\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmathematical_accuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogical_consistency\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompleteness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclarity_and_coherence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformulas_principles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massumptions_made\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverall_correctness\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    202\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditionalProperties\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_tokens=1024,\u001b[39;49;00m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# top_p=0.5\u001b[39;49;00m\n\u001b[0;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    213\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAW MODEL OUTPUT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1008\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1007\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1023\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1022\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1026\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1027\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1032\u001b[0m )\n",
      "\u001b[1;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'message': 'all completion attempts failed: glm-4.5-flash (service temporarily unavailable due to high demand. Please retry in a moment)', 'type': 'api_error'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "Pineapple_api_key = os.getenv(\"ANANNAS_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def safe_json_loads(text):\n",
    "    if not text or not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Try to extract first JSON object\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\")\n",
    "        if start != -1 and end != -1:\n",
    "            try:\n",
    "                return json.loads(text[start:end+1])\n",
    "            except json.JSONDecodeError:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_eval_prompt(problem_id, elaborate_solution, model_output, question):\n",
    "    prompt = f\"\"\"You are an expert physics problem evaluator. Your task is to meticulously and STRICTLY evaluate an AI-generated solution based on its own merits and against the provided elaborated solution steps.\n",
    "\n",
    "Evaluate the AI-generated solution based on the following categories and scoring guidelines. Provide your evaluation STRICTLY as a JSON object.\n",
    "\n",
    "Evaluation Categories and Scoring Guidelines:\n",
    "\n",
    "1. **mathematical_accuracy**: (Score 1-5)\n",
    "   How correct are the AI's calculations, numerical answers, and units?\n",
    "   * 5: All calculations, numerical results, and units are perfectly correct\n",
    "   * 4: Minor calculation error, but underlying method is sound\n",
    "   * 3: Several minor errors, or one significant calculation error\n",
    "   * 2: Major calculation errors or fundamental misunderstandings\n",
    "   * 1: Almost all calculations are incorrect or missing\n",
    "\n",
    "2. **logical_consistency**: (Score 1-5)\n",
    "   Does the AI solution follow a logical step-by-step progression?\n",
    "   * 5: Perfect logical flow, impeccable reasoning\n",
    "   * 4: Mostly logical, minor unclear step\n",
    "   * 3: Some logical gaps or inconsistencies\n",
    "   * 2: Significant logical flaws\n",
    "   * 1: Illogical or incoherent\n",
    "\n",
    "3. **completeness**: (Score 1-5)\n",
    "   Does the AI-generated solution address all parts of the problem?\n",
    "   * 5: All parts fully addressed\n",
    "   * 4: Minor aspect overlooked\n",
    "   * 3: Significant part ignored\n",
    "   * 2: Only small portion addressed\n",
    "   * 1: Largely unaddressed\n",
    "\n",
    "4. **clarity_and_coherence**: (Score 1-5)\n",
    "   Is the AI's explanation clear and easy to understand?\n",
    "   * 5: Exceptionally clear and well-structured\n",
    "   * 4: Clear with minor areas for improvement\n",
    "   * 3: Generally understandable but verbose or unclear in parts\n",
    "   * 2: Difficult to understand\n",
    "   * 1: Incomprehensible\n",
    "\n",
    "5. **formulas_principles**: (Score 1-5)\n",
    "   Are correct physical formulas and principles applied correctly?\n",
    "   * 5: All necessary formulas correctly identified and applied\n",
    "   * 4: Mostly correct with minor errors\n",
    "   * 3: Some incorrect formulas or significant misapplication\n",
    "   * 2: Major errors in formula/principle selection\n",
    "   * 1: Completely inappropriate formulas\n",
    "\n",
    "6. **assumptions_made**: (Score 1-5)\n",
    "   Are AI assumptions explicit, justified, and reasonable?\n",
    "   * 5: All assumptions explicitly stated and well-justified\n",
    "   * 4: Most assumptions stated and reasonable\n",
    "   * 3: Some key assumptions missing or questionable\n",
    "   * 2: Major unreasonable assumptions\n",
    "   * 1: Inappropriate or absent assumptions\n",
    "\n",
    "7. **overall_correctness**: (Score 0-10)\n",
    "   How correct is the AI's approach and final answer overall?\n",
    "   * 10: Perfect solution\n",
    "   * 8-9: Excellent, very minor flaws\n",
    "   * 6-7: Good, largely correct\n",
    "   * 4-5: Partially correct\n",
    "   * 2-3: Mostly incorrect\n",
    "   * 0-1: Completely incorrect\n",
    "\n",
    "Physics Question: {question}\n",
    "\n",
    "Problem ID: {problem_id}\n",
    "\n",
    "Elaborated Solution Steps: {elaborate_solution}\n",
    "\n",
    "AI-Generated Solution to Evaluate: {model_output}\n",
    "\n",
    "Provide ONLY a JSON object with the problem_id and scores for each category.\n",
    "\n",
    "Example JSON format:\n",
    "{{\n",
    "  \"problem_id\": \"{problem_id}\",\n",
    "  \"mathematical_accuracy\": <score_1_to_5>,\n",
    "  \"logical_consistency\": <score_1_to_5>,\n",
    "  \"completeness\": <score_1_to_5>,\n",
    "  \"clarity_and_coherence\": <score_1_to_5>,\n",
    "  \"formulas_principles\": <score_1_to_5>,\n",
    "  \"assumptions_made\": <score_1_to_5>,\n",
    "  \"overall_correctness\": <score_0_to_10>\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def process_jsonl(in_path: Path, out_path: Path = None):\n",
    "    \"\"\"\n",
    "    Process JSONL file and evaluate each entry using LLM judge\n",
    "    \"\"\"\n",
    "    if out_path is None:\n",
    "        out_path = in_path.parent / f\"{in_path.stem}_evaluated.json\"\n",
    "    \n",
    "    qwen_eval_data = []\n",
    "    prob_ids_processed = set()\n",
    "    \n",
    "    # Load previously evaluated items if output file exists\n",
    "    if os.path.exists(out_path):\n",
    "        with open(out_path, 'r', encoding='utf-8') as f:\n",
    "            judge_data = json.load(f)\n",
    "            if isinstance(judge_data, list):\n",
    "                qwen_eval_data.extend(i for i in judge_data if isinstance(i, dict))\n",
    "                prob_ids_processed.update(i.get('problem_id') for i in qwen_eval_data if i.get('problem_id'))\n",
    "        logger.info(f\"Loaded {len(qwen_eval_data)} previously evaluated items from {out_path}\")\n",
    "    \n",
    "    ids_left = []\n",
    "    with open(in_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            problem_id = item.get('problem_id')\n",
    "            if problem_id not in prob_ids_processed:\n",
    "                if item.get('model_output') and item.get('elaborate_solution'):\n",
    "                    ids_left.append(item)\n",
    "    \n",
    "    logger.info(f\"Found {len(ids_left)} items to evaluate\")\n",
    "    \n",
    "    if not ids_left:\n",
    "        logger.info(\"No new items to evaluate\")\n",
    "        return qwen_eval_data\n",
    "    \n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.anannas.ai/v1\",\n",
    "        api_key=Pineapple_api_key\n",
    "    )\n",
    "    \n",
    "    for j, item in enumerate(ids_left):\n",
    "        problem_id = item.get('problem_id')\n",
    "        logger.info(f\"Processing item {j + 1}/{len(ids_left)}: {problem_id}\")\n",
    "        \n",
    "        prompt = fetch_eval_prompt(\n",
    "            problem_id,\n",
    "            item.get('elaborate_solution'),\n",
    "            item.get('model_output'),\n",
    "            item.get('question', '')\n",
    "        )\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"glm-4.5-flash\", \n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"physics_evaluation\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"problem_id\": {\"type\": \"string\"},\n",
    "                            \"mathematical_accuracy\": {\"type\": \"integer\"},\n",
    "                            \"logical_consistency\": {\"type\": \"integer\"},\n",
    "                            \"completeness\": {\"type\": \"integer\"},\n",
    "                            \"clarity_and_coherence\": {\"type\": \"integer\"},\n",
    "                            \"formulas_principles\": {\"type\": \"integer\"},\n",
    "                            \"assumptions_made\": {\"type\": \"integer\"},\n",
    "                            \"overall_correctness\": {\"type\": \"integer\"}\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"problem_id\", \"mathematical_accuracy\", \"logical_consistency\",\n",
    "                            \"completeness\", \"clarity_and_coherence\", \"formulas_principles\",\n",
    "                            \"assumptions_made\", \"overall_correctness\"\n",
    "                        ],\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            temperature=0.3,\n",
    "            # max_tokens=1024,\n",
    "            # top_p=0.5\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        logger.info(f\"RAW MODEL OUTPUT:\\n{repr(content)}\")\n",
    "\n",
    "        \n",
    "        eval_result = safe_json_loads(content)\n",
    "        if eval_result is None:\n",
    "            logger.error(f\"Invalid JSON for problem_id={problem_id}\")\n",
    "            continue\n",
    "\n",
    "        qwen_eval_data.append(eval_result)\n",
    "        \n",
    "        # checkpointing evals \n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(qwen_eval_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"Evaluated {problem_id}: Overall correctness = {eval_result.get('overall_correctness')}/10\")\n",
    "    \n",
    "    logger.info(f\"Evaluation complete. Total evaluated: {len(qwen_eval_data)}\")\n",
    "    logger.info(f\"Results saved to: {out_path}\")\n",
    "    \n",
    "    return qwen_eval_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = Path(r\"D:\\physics-reasoning\\smol-phy-reasoning\\qwen_final_phy_eval.json\")\n",
    "    output_file = Path(r\"D:\\physics-reasoning\\smol-phy-reasoning\\qwen_final_phy_eval_results.json\")\n",
    "    \n",
    "    results = process_jsonl(input_file, output_file)\n",
    "    print(f\"\\nEvaluation Summary:\")\n",
    "    print(f\"Total items evaluated: {len(results)}\")\n",
    "    if results:\n",
    "        avg_score = sum(r.get('overall_correctness', 0) for r in results) / len(results)\n",
    "        print(f\"Average overall correctness: {avg_score:.2f}/10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
